{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: get: command not found\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import librosa.display\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import numba \n",
    "import sklearn \n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Flatten, Conv1D, Input, MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_path = 'data/train'\n",
    "samples, sr = librosa.load(train_audio_path+'yes/0a7c2a8d_nohash_0.wav', sr=16000)\n",
    "ipd.Audio(samples, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_audio_path)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find count of each label and plot \n",
    "labels = os.listdir(train_audio_path)\n",
    "no_of_recordings=[]\n",
    "for label in labels: \n",
    "  waves = [f for f in os.listdir(train_audio_path + label) if f.endswith('.wav')]\n",
    "  no_of_recordings.append(len(waves))\n",
    "\n",
    "\n",
    "# plot \n",
    "plt.figure(figsize=(30,5))\n",
    "index = np.arange(len(labels))\n",
    "plt.bar(index, no_of_recordings)\n",
    "plt.xlabel('Commands', fontsize=12)\n",
    "plt.ylabel('No. of recordings', fontsize=12)\n",
    "plt.xticks(index, labels, fontsize=15, rotation=60)\n",
    "plt.title('No. of recordings for each command')\n",
    "plt.show()\n",
    "\n",
    "labels=['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_of_recordings=[]\n",
    "for label in labels: \n",
    "  waves = [f for f in os.listdir(train_audio_path + '/' + label) if f.endswith('.wav')]\n",
    "  for wav in waves:\n",
    "    sample_rate, samples = wavfile.read(train_audio_path + '/' + label + '/' + wav)\n",
    "    duration_of_recordings.append(float(len(samples)/sample_rate))\n",
    "\n",
    "plt.hist(np.array(duration_of_recordings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "  print(label)\n",
    "  waves = [f for f in os.listdir(train_audio_path + '/' + label) if f.endswith('.wav')]\n",
    "  for wav in waves:\n",
    "    samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "    samples = librosa.resample(samples, sample_rate, 8000)\n",
    "    if(len(samples) == 8000):\n",
    "      all_wave.append(samples)\n",
    "      all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the output labels to integer encoded\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(all_label)\n",
    "classes = list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, convert the integer encoded labels to a one-hot vector since it is a multi-classification problem.\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y = np_utils.to_categorical(y, num_classes=len(labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the 2D array to 3D since the input to the conv1d must be a 3D array.\n",
    "all_waves = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave), np.array(y), stratify = y, test_size = 0.2, random_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers.pooling import MaxPooling1D\n",
    "# model \n",
    "\n",
    "\n",
    "inputs = Input(shape=(8000,1))\n",
    "\n",
    "# first Conv1D layer \n",
    "conv = Conv1D(8, 13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "# second layer\n",
    "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "# third layer\n",
    "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "# fourth layer \n",
    "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "# flatten layer \n",
    "conv = Flatten()(conv)\n",
    "\n",
    "# Dense Layer \n",
    "conv = Dense(256, activation='relu')(conv)\n",
    "conv = Dropout(0.03)(conv)\n",
    "\n",
    "# Dense layer 2\n",
    "conv = Dense(128, activation='relu')(conv)\n",
    "conv = Dropout(0.03)(conv)\n",
    "\n",
    "outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "\n",
    "model = Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3358073929bd3d27ff594bc6528257efc4213b34ba9d7c6bd240dce3a23a83d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
