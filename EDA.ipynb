{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "explore datasets and make dataframes containing metadata for each set if one is not provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVSP-ESD Dataset \n",
    "\n",
    "source: https://www.kaggle.com/dejolilandry/asvpesdspeech-nonspeech-emotional-utterances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation \n",
    "Since the dataset didnt come with a CSV file containing the metadata we'll create a dataframe that contains the Path to the Wav file and it Class which is what emotion it has been labeled as. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from the Kaggle Dataset Descri\n",
    "\n",
    "Each wav file in the dataset consists of numerical identifiers. \n",
    "\n",
    "Filename identifiers:\n",
    "Modality ( 03 = audio-only).\n",
    "Vocal channel on s(01 = speech, 02 = npeech).\n",
    "Emotion ( 01 = boredom, 02 = neutral, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised, 09 = excited, 10 = pleasure, 11 = pain, 12 = disappointment, 13 = others).\n",
    "Emotional intensity (01 = normal, 02 = high).\n",
    "Statement (as itâ€™s non scripted this refer to the number of sample select per actor folder ).\n",
    "Actor ( even numbered acteurs are male, odd numbered actors are female).\n",
    "Age(01 = above 65, 02 = between 20~64, 03 = under 20,04=new born).\n",
    "Source of downloading (01 =website , 02 = youtube channel, 03= movies).\n",
    "Language(01=Chinese , 02=English ,04 = french , others).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    1: 'boredom', \n",
    "    2: 'neutral',\n",
    "    3: 'happy',\n",
    "    4: 'sad',\n",
    "    5: 'angry',\n",
    "    6: 'fearful',\n",
    "    7: 'disgust', \n",
    "    8: 'surprised',\n",
    "    9: 'excited', \n",
    "    10: 'pleasure',\n",
    "    11: 'pain', \n",
    "    12: 'disappointment', \n",
    "    13: 'others'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by taking a look at how the data is labeled we can decide how to make classification for our problem. Lets start simple and just use the Emotion label. Later we can try classifying other labels like age and gender. We'll also only use files labeled as speech, later we'll use the non speech files for data augmentation but more on that later. for now lets make a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03', '01', '02', '01', '06', '13', '02', '03', '01']\n"
     ]
    }
   ],
   "source": [
    "# lets practice taking the path strings apart \n",
    "ster = \"/Users/stephen/Desktop/Speech_Recognition/Data/ASVP-ESD_UPDATE/Audio/actor_13/03-01-02-01-06-13-02-03-01.wav\"\n",
    "part = ster.split('/')[-1]\n",
    "part = part.split('.')[0]\n",
    "part = part.split('-')\n",
    "print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at all the folders  \n",
    "\n",
    "\n",
    "\n",
    "# iterate through files and \n",
    "for dir in dir_list:\n",
    "    # extract contents from each folder \n",
    "    actor = os.listdir(audio_path + dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/Users/stephen/Desktop/Speech_Recognition/Data/ASVP-ESD_UPDATE/Audio/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/ywsrz7k170vbk8511l1h_6840000gn/T/ipykernel_23238/3261295192.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# extract contents from each folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# go through each file in each folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/Users/stephen/Desktop/Speech_Recognition/Data/ASVP-ESD_UPDATE/Audio/.DS_Store'"
     ]
    }
   ],
   "source": [
    "# string representing PATH for folder containing data\n",
    "audio_path = '/Users/stephen/Desktop/Speech_Recognition/Data/ASVP-ESD_UPDATE/Audio/'\n",
    "\n",
    "# the dataset is organized into folders for each actor/actress. the listdir method will list all contained folders \n",
    "dir_list = os.listdir(audio_path)\n",
    "\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "file_fold = []\n",
    "\n",
    "# iterate through files and \n",
    "for dir in dir_list:\n",
    "    # extract contents from each folder \n",
    "    actor = os.listdir(audio_path + dir)\n",
    "    # go through each file in each folder \n",
    "    for file in actor: \n",
    "        part = file.split('.')[0] # ignore the .wav\n",
    "        part = part.split('-')\n",
    "        # the second part represents speech or non speech \n",
    "        if part[1] == '01': # 01 represents Speech \n",
    "            # third part represents emotion \n",
    "            file_emotion.append(int(part[2]))\n",
    "            file_path.append('/' + file)\n",
    "            file_fold.append(dir)\n",
    "\n",
    "\n",
    "\n",
    "# dataframe for emotion of files \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files \n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "\n",
    "# dataframe for names of folders \n",
    "fold_df = pd.DataFrame(file_fold, columns=['Folder'])\n",
    "\n",
    "metadata = pd.concat([emotion_df, path_df, fold_df], axis=1)\n",
    "\n",
    "# change integers to actual emotions. \n",
    "metadata.Emotions.replace(labels_dict, inplace=True)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3358073929bd3d27ff594bc6528257efc4213b34ba9d7c6bd240dce3a23a83d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
