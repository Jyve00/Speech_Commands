{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "explore datasets and make dataframes containing metadata for each set if one is not provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVSP-ESD Dataset \n",
    "\n",
    "source: https://www.kaggle.com/dejolilandry/asvpesdspeech-nonspeech-emotional-utterances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation \n",
    "Since the dataset didnt come with a CSV file containing the metadata we'll create a dataframe that contains the Path to the Wav file and it Class which is what emotion it has been labeled as. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from the Kaggle Dataset Descri\n",
    "\n",
    "Each wav file in the dataset consists of numerical identifiers. \n",
    "\n",
    "Filename identifiers:\n",
    "Modality ( 03 = audio-only).\n",
    "Vocal channel on s(01 = speech, 02 = npeech).\n",
    "Emotion ( 01 = boredom, 02 = neutral, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised, 09 = excited, 10 = pleasure, 11 = pain, 12 = disappointment, 13 = others).\n",
    "Emotional intensity (01 = normal, 02 = high).\n",
    "Statement (as itâ€™s non scripted this refer to the number of sample select per actor folder ).\n",
    "Actor ( even numbered acteurs are male, odd numbered actors are female).\n",
    "Age(01 = above 65, 02 = between 20~64, 03 = under 20,04=new born).\n",
    "Source of downloading (01 =website , 02 = youtube channel, 03= movies).\n",
    "Language(01=Chinese , 02=English ,04 = french , others).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    1: 'boredom', \n",
    "    2: 'neutral',\n",
    "    3: 'happy',\n",
    "    4: 'sad',\n",
    "    5: 'angry',\n",
    "    6: 'fearful',\n",
    "    7: 'disgust', \n",
    "    8: 'surprised',\n",
    "    9: 'excited', \n",
    "    10: 'pleasure',\n",
    "    11: 'pain', \n",
    "    12: 'disappointment', \n",
    "    13: 'others'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by taking a look at how the data is labeled we can decide how to make classification for our problem. Lets start simple and just use the Emotion label. Later we can try classifying other labels like age and gender. We'll also only use files labeled as speech, later we'll use the non speech files for data augmentation but more on that later. for now lets make a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['03', '01', '02', '01', '06', '13', '02', '03', '01']\n"
     ]
    }
   ],
   "source": [
    "# lets practice taking the path strings apart \n",
    "ster = \"/Users/stephen/Desktop/Speech_Recognition/Data/ASVP-ESD_UPDATE/Audio/actor_13/03-01-02-01-06-13-02-03-01.wav\"\n",
    "part = ster.split('/')[-1]\n",
    "part = part.split('.')[0]\n",
    "part = part.split('-')\n",
    "print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor_16\n",
      "actor_29\n",
      "actor_11\n",
      "actor_27\n",
      "actor_18\n",
      "actor_20\n",
      "actor_74\n",
      "actor_80\n",
      "actor_87\n",
      "actor_73\n",
      "actor_103\n",
      "actor_45\n",
      "actor_89\n",
      "actor_42\n",
      "actor_104\n",
      "actor_21\n",
      "actor_26\n",
      "actor_19\n",
      "actor_10\n",
      "actor_17\n",
      "actor_28\n",
      "actor_88\n",
      "actor_105\n",
      "actor_43\n",
      "actor_44\n",
      "actor_102\n",
      "actor_72\n",
      "actor_86\n",
      "actor_81\n",
      "actor_75\n",
      "actor_5\n",
      "actor_2\n",
      ".DS_Store\n",
      "actor_3\n",
      "actor_4\n",
      "actor_57\n",
      "actor_68\n",
      "actor_50\n",
      "actor_66\n",
      "actor_59\n",
      "actor_61\n",
      "actor_35\n",
      "actor_32\n",
      "actor_60\n",
      "actor_67\n",
      "actor_58\n",
      "actor_51\n",
      "actor_56\n",
      "actor_69\n",
      "actor_33\n",
      "actor_34\n",
      "actor_84\n",
      "actor_70\n",
      "actor_48\n",
      "actor_77\n",
      "actor_83\n",
      "actor_41\n",
      "actor_79\n",
      "actor_100\n",
      "actor_46\n",
      "actor_12\n",
      "actor_15\n",
      "actor_23\n",
      "actor_24\n",
      "actor_78\n",
      "actor_47\n",
      "actor_101\n",
      "actor_106\n",
      "actor_40\n",
      "actor_49\n",
      "actor_82\n",
      "actor_76\n",
      "actor_71\n",
      "actor_85\n",
      "actor_25\n",
      "actor_22\n",
      "actor_14\n",
      "actor_13\n",
      "actor_1\n",
      "actor_6\n",
      "actor_8\n",
      "actor_9\n",
      "actor_7\n",
      "actor_0\n",
      "actor_31\n",
      "actor_36\n",
      "actor_38\n",
      "actor_53\n",
      "actor_54\n",
      "actor_62\n",
      "actor_65\n",
      "actor_91\n",
      "actor_39\n",
      "actor_37\n",
      "actor_30\n",
      "actor_90\n",
      "actor_64\n",
      "actor_63\n",
      "actor_55\n",
      "actor_52\n"
     ]
    }
   ],
   "source": [
    "# take a look at all the folders  \n",
    "\n",
    "# string representing PATH for folder containing data\n",
    "audio_path = '/Users/stephen/Desktop/Speech_Recognition/Data/ASVP-ESD_UPDATE/Audio/'\n",
    "\n",
    "# the dataset is organized into folders for each actor/actress. the listdir method will list all contained folders \n",
    "dir_list = os.listdir(audio_path)\n",
    "\n",
    "# iterate through files and \n",
    "for dir in dir_list:\n",
    "    print(dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you might not be able to see it from the long list of folders but DS_Store shows up and will cause an error if it is not delt with properly. We'll simply add a  conditional in the following function that will ignore the DS_Store file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor_16\n",
      "actor_29\n",
      "actor_11\n",
      "actor_27\n",
      "actor_18\n",
      "actor_20\n",
      "actor_74\n",
      "actor_80\n",
      "actor_87\n",
      "actor_73\n",
      "actor_103\n",
      "actor_45\n",
      "actor_89\n",
      "actor_42\n",
      "actor_104\n",
      "actor_21\n",
      "actor_26\n",
      "actor_19\n",
      "actor_10\n",
      "actor_17\n",
      "actor_28\n",
      "actor_88\n",
      "actor_105\n",
      "actor_43\n",
      "actor_44\n",
      "actor_102\n",
      "actor_72\n",
      "actor_86\n",
      "actor_81\n",
      "actor_75\n",
      "actor_5\n",
      "actor_2\n",
      "actor_3\n",
      "actor_4\n",
      "actor_57\n",
      "actor_68\n",
      "actor_50\n",
      "actor_66\n",
      "actor_59\n",
      "actor_61\n",
      "actor_35\n",
      "actor_32\n",
      "actor_60\n",
      "actor_67\n",
      "actor_58\n",
      "actor_51\n",
      "actor_56\n",
      "actor_69\n",
      "actor_33\n",
      "actor_34\n",
      "actor_84\n",
      "actor_70\n",
      "actor_48\n",
      "actor_77\n",
      "actor_83\n",
      "actor_41\n",
      "actor_79\n",
      "actor_100\n",
      "actor_46\n",
      "actor_12\n",
      "actor_15\n",
      "actor_23\n",
      "actor_24\n",
      "actor_78\n",
      "actor_47\n",
      "actor_101\n",
      "actor_106\n",
      "actor_40\n",
      "actor_49\n",
      "actor_82\n",
      "actor_76\n",
      "actor_71\n",
      "actor_85\n",
      "actor_25\n",
      "actor_22\n",
      "actor_14\n",
      "actor_13\n",
      "actor_1\n",
      "actor_6\n",
      "actor_8\n",
      "actor_9\n",
      "actor_7\n",
      "actor_0\n",
      "actor_31\n",
      "actor_36\n",
      "actor_38\n",
      "actor_53\n",
      "actor_54\n",
      "actor_62\n",
      "actor_65\n",
      "actor_91\n",
      "actor_39\n",
      "actor_37\n",
      "actor_30\n",
      "actor_90\n",
      "actor_64\n",
      "actor_63\n",
      "actor_55\n",
      "actor_52\n"
     ]
    }
   ],
   "source": [
    "for dir in dir_list:\n",
    "    if dir != \".DS_Store\":\n",
    "        print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "      <th>Folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/03-01-02-01-02-16-03-03-01.wav</td>\n",
       "      <td>actor_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>angry</td>\n",
       "      <td>/03-01-05-02-07-16-03-03-01.wav</td>\n",
       "      <td>actor_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/03-01-02-01-13-16-03-03-01.wav</td>\n",
       "      <td>actor_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/03-01-02-01-05-16-03-03-01.wav</td>\n",
       "      <td>actor_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>angry</td>\n",
       "      <td>/03-01-05-02-06-16-03-03-01.wav</td>\n",
       "      <td>actor_16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Emotions                             Path    Folder\n",
       "0  neutral  /03-01-02-01-02-16-03-03-01.wav  actor_16\n",
       "1    angry  /03-01-05-02-07-16-03-03-01.wav  actor_16\n",
       "2  neutral  /03-01-02-01-13-16-03-03-01.wav  actor_16\n",
       "3  neutral  /03-01-02-01-05-16-03-03-01.wav  actor_16\n",
       "4    angry  /03-01-05-02-06-16-03-03-01.wav  actor_16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string representing PATH for folder containing data\n",
    "audio_path = '/Users/stephen/Desktop/Speech_Recognition/Data/ASVP-ESD_UPDATE/Audio/'\n",
    "\n",
    "# the dataset is organized into folders for each actor/actress. the listdir method will list all contained folders \n",
    "dir_list = os.listdir(audio_path)\n",
    "\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "file_fold = []\n",
    "\n",
    "# iterate through files and \n",
    "for dir in dir_list:\n",
    "    if dir != \".DS_Store\":\n",
    "    # extract contents from each folder \n",
    "        actor = os.listdir(audio_path + dir)\n",
    "    # go through each file in each folder \n",
    "        for file in actor: \n",
    "            part = file.split('.')[0] # ignore the .wav\n",
    "            part = part.split('-')\n",
    "            # the second part represents speech or non speech \n",
    "            if part[1] == '01': # 01 represents Speech \n",
    "                # third part represents emotion \n",
    "                file_emotion.append(int(part[2]))\n",
    "                file_path.append('/' + file)\n",
    "                file_fold.append(dir)\n",
    "\n",
    "\n",
    "\n",
    "# dataframe for emotion of files \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "# dataframe for path of files \n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "\n",
    "# dataframe for names of folders \n",
    "fold_df = pd.DataFrame(file_fold, columns=['Folder'])\n",
    "\n",
    "metadata = pd.concat([emotion_df, path_df, fold_df], axis=1)\n",
    "\n",
    "# change integers to actual emotions. \n",
    "metadata.Emotions.replace(labels_dict, inplace=True)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11838"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Emotions                                   Path    Folder\n",
       "0     neutral        /03-01-02-01-02-16-03-03-01.wav  actor_16\n",
       "1       angry        /03-01-05-02-07-16-03-03-01.wav  actor_16\n",
       "2     neutral        /03-01-02-01-13-16-03-03-01.wav  actor_16\n",
       "3     neutral        /03-01-02-01-05-16-03-03-01.wav  actor_16\n",
       "4       angry        /03-01-05-02-06-16-03-03-01.wav  actor_16\n",
       "...       ...                                    ...       ...\n",
       "3941    angry        /03-01-05-01-90-52-02-02-03.wav  actor_52\n",
       "3942  neutral  /03-01-02-01-01-52-02-02-02-12-01.wav  actor_52\n",
       "3943    angry        /03-01-05-01-91-52-02-02-03.wav  actor_52\n",
       "3944    angry        /03-01-05-02-80-52-02-02-03.wav  actor_52\n",
       "3945    angry        /03-01-05-01-87-52-02-02-03.wav  actor_52\n",
       "\n",
       "[3946 rows x 3 columns]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3946, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3358073929bd3d27ff594bc6528257efc4213b34ba9d7c6bd240dce3a23a83d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('torch_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
